import os
import uuid
import json
from datetime import datetime, timedelta

# ==========================================
#  1. Imports ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
# ==========================================
# Database & Cache
from sqlalchemy import create_engine, Column, String, Text, DateTime
from sqlalchemy.dialects.postgresql import UUID, JSONB
from sqlalchemy.orm import declarative_base, sessionmaker

# LangChain & LLM
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field

# Vector DB
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_postgres import PGVector

# SQL Agent
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import create_sql_agent

# ==========================================
#  2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (Configurations)
# ==========================================
DB_URI = "postgresql+psycopg2://postgres:User%40FujikuraN1@localhost/llm_db"
COLLECTION_NAME = "company_documents_md_6" # ‡∏ä‡∏∑‡πà‡∏≠ Collection 

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ LLM ‡∏´‡∏•‡∏±‡∏Å (‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏µ‡πà LiteLLM/Ollama)
LLM_MODEL_NAME = "qwen-3"
LLM_API_KEY = "sk-hXu_Q9kM5BWMeMVbrpYsdg" 
LLM_BASE_URL = "http://localhost:4000/v1"

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Engine ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡πà‡∏≠ Database
engine = create_engine(DB_URI)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# ==========================================
#  3. ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á Cache ‡πÉ‡∏ô PostgreSQL
# ==========================================
class LlmPromptCache(Base):
    __tablename__ = "llm_prompt_cache"
    __table_args__ = {"schema": "public"} # ‡πÉ‡∏ä‡πâ schema public ‡∏õ‡∏Å‡∏ï‡∏¥ ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô llm ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    model = Column(String, index=True)           
    input_model = Column(Text, index=True)       
    output_model = Column(Text)                  
    condition = Column(Text, nullable=True)      
    meta_data = Column("meta", JSONB, nullable=True) 
    expires_date = Column(DateTime)              
    created_at = Column(DateTime, default=datetime.utcnow) 

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á Cache ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
Base.metadata.create_all(bind=engine)

# ==========================================
#  4. ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (Structured Output Pydantic)
# ==========================================
class StructuredChatResponse(BaseModel):
    answer: str = Field(description="‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÅ‡∏•‡∏∞ List (Bullet points) ‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)")
    sentiment: str = Field(description="‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å User (‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÅ‡∏Ñ‡πà Positive, Negative ‡∏´‡∏£‡∏∑‡∏≠ Neutral)")
    confidence_score: float = Field(description="‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á AI ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà 0.0 ‡∏ñ‡∏∂‡∏á 1.0 (‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö >0.8)")

# ==========================================
#  5. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Vector & SQL)
# ==========================================
def get_vector_context(query: str) -> str:
    """ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ (Markdown) """
    embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")
    vector_store = PGVector(
        embeddings=embeddings, collection_name=COLLECTION_NAME, connection=engine, use_jsonb=True
    )
    results = vector_store.similarity_search_with_score(query, k=5)
    
    context = ""
    for doc, score in results:
        header = doc.metadata.get('Header 3', '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ')
        context += f"[{header}] {doc.page_content}\n"
    
    return context if context else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠"

def get_sql_context(query: str) -> str:
    """ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQL (Machine Logs) """
    db = SQLDatabase.from_uri(DB_URI, include_tables=["machine_logs"])
    llm = ChatOpenAI(model=LLM_MODEL_NAME, api_key=LLM_API_KEY, base_url=LLM_BASE_URL, temperature=0)
    
    agent_executor = create_sql_agent(
        llm, db=db, agent_type="zero-shot-react-description", verbose=False, handle_parsing_errors=True
    )
    
    try:
        response = agent_executor.invoke({"input": query})
        return response['output']
    except Exception as e:
        return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}"

def route_query(query: str) -> str:
    """ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô (Router) """
    sql_keywords = ["oee", "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£", "machine", "‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå", "log", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"]
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£ ‡πÉ‡∏´‡πâ‡πÑ‡∏õ SQL ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏Ñ‡πâ‡∏ô‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ (Vector)
    if any(keyword in query.lower() for keyword in sql_keywords):
        return "SQL"
    return "VECTOR"

# ==========================================
#  6. Workflow ‡∏´‡∏•‡∏±‡∏Å 
# ==========================================
def run_super_agent(query: str):
    # print(f"\n[{datetime.now().strftime('%H:%M:%S')}] ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: '{query}'")
    db_session = SessionLocal()
    
    try:
        now = datetime.utcnow()
        
        # --- Step A: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Cache ---
        cached_record = db_session.query(LlmPromptCache).filter(
            LlmPromptCache.input_model == query,
            LlmPromptCache.expires_date > now  
        ).first()

        if cached_record:
            # print(" [Cache Hit] ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏î‡∏¥‡∏° (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô AI)")
            return json.loads(cached_record.output_model)

        # print(" [Cache Miss] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤...")

        # --- Step B: ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö ---
        route = route_query(query)
        # print(f" ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á: ‡∏ß‡∏¥‡πà‡∏á‡πÑ‡∏õ‡∏Ñ‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà [{route}]")
        
        if route == "SQL":
            raw_context = get_sql_context(query)
        else:
            raw_context = get_vector_context(query)
            
        # print(f" ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡∏´‡∏≤‡πÑ‡∏î‡πâ: {raw_context[:100]}...")

# --- Step C: ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LLM ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏ü‡∏≠‡∏£‡πå‡πÅ‡∏°‡∏ï ---
        
        # üü¢ 1. ‡∏™‡∏±‡πà‡∏á‡∏õ‡∏£‡∏¥‡πâ‡∏ô‡∏ó‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏≠‡∏≠‡∏Å‡∏ó‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Vector DB ‡∏î‡∏∂‡∏á Bullet points ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°!
        print("\nüîç [Debug] ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏≠‡πà‡∏≤‡∏ô:\n" + "-"*40)
        print(raw_context)
        print("-" * 40)
        
        system_instruction = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô ‡∏à‡∏á‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        
‡∏Å‡∏é‡∏Å‡∏ï‡∏¥‡∏Å‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î:
1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô 100% ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡πÜ (Bullet points) ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏µ‡∏î (-) 
2. ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏ö‡∏£‡∏±‡∏î ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏£‡∏ß‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏•‡∏∞‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏¥‡πâ‡∏á‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î 
3. ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÇ‡∏î‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡πÜ ‡πÑ‡∏ß‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:
{raw_context}"""

        messages = [
            SystemMessage(content=system_instruction),
            HumanMessage(content=query)
        ]
        
        llm = ChatOpenAI(model=LLM_MODEL_NAME, api_key=LLM_API_KEY, base_url=LLM_BASE_URL, temperature=0)
        structured_llm = llm.with_structured_output(StructuredChatResponse)
        response_object = structured_llm.invoke(messages)
        
        #  2. ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ü‡πà‡∏≤ Warning ‡∏™‡∏µ‡πÅ‡∏î‡∏á‡∏ñ‡∏≤‡∏ß‡∏£: ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ .model_dump() ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏£‡∏á‡πÜ ‡πÅ‡∏ó‡∏ô
        if hasattr(response_object, 'parsed') and response_object.parsed is not None:
            ans = response_object.parsed.answer
            sent = response_object.parsed.sentiment
            conf = response_object.parsed.confidence_score
        else:
            ans = getattr(response_object, 'answer', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö')
            sent = getattr(response_object, 'sentiment', 'Neutral')
            conf = getattr(response_object, 'confidence_score', 0.0)

        final_answer_dict = {
            "answer": str(ans),
            "sentiment": str(sent),
            "confidence_score": float(conf)
        }

        # --- Step D: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏•‡∏á Cache ---
        new_cache = LlmPromptCache(
            model=LLM_MODEL_NAME,
            input_model=query,
            output_model=json.dumps(final_answer_dict, ensure_ascii=False), 
            condition=route,
            meta_data={"source_used": route},
            expires_date=now + timedelta(days=1) 
        )
        db_session.add(new_cache)
        db_session.commit() 

        return final_answer_dict

    except Exception as e:
        print(f" ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
        return {"answer": "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î", "sentiment": "Neutral", "confidence_score": 0.0}
    finally:
        db_session.close()

# ==========================================
#  7. ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏ó (Terminal UI)
# ==========================================
if __name__ == "__main__":
    print("=" * 60)
    print(" ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö(‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å)")
    print("=" * 60)
    
    while True:
        user_input = input("\n ‡∏Ñ‡∏∏‡∏ì: ")
        if user_input.lower() in ['exit', 'quit', '‡∏≠‡∏≠‡∏Å']:
            print("‡∏ö‡πä‡∏≤‡∏¢‡∏ö‡∏≤‡∏¢!")
            break
            
        result = run_super_agent(user_input)
        
        print("\n" + "-"*40)
        print(f" ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö AI: {result.get('answer')}")
        print(f" ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {result.get('sentiment')}")
        print(f" ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {result.get('confidence_score')}")
        print("-" * 40)